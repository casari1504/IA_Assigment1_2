{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584b150b-8cec-4db4-a1a8-85b4866b6dfa",
   "metadata": {},
   "source": [
    "# DISCLAIMER\n",
    "The `random_state` is set to 42 because it is a common convention choice in tutorials and assignments (a \"fun convention\" from *The Hitchhiker's Guide to the Galaxy*). You can pick any integer, but different integers produce different sequence of randomness so your results will not be identical across different seeds. Using a fixed `random_state` ensures reproducibility of results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fcbda0-57fc-4faf-99d5-7775b455a7d8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1afd4f37-c368-4974-b820-ce91364a9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV,cross_validate, StratifiedKFold,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report,precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729978fd-af41-4daa-bba0-9a08e2748501",
   "metadata": {},
   "source": [
    "### Load wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6c3104-6bbc-4b0a-ac1d-5123b36b5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define variables X, Y and df\n",
    "wine = datasets.load_wine()\n",
    "X=wine.data\n",
    "Y=wine.target\n",
    "df=pd.DataFrame(X,columns=wine.feature_names)\n",
    "df.head()\n",
    "\n",
    "#changing name of troublesome column\n",
    "i = wine.feature_names.index('od280/od315_of_diluted_wines')\n",
    "wine.feature_names[i] = 'ratio_of_diluted_wines'\n",
    "df = df.rename(columns={'od280/od315_of_diluted_wines': 'ratio_of_diluted_wines'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fac922-f0a0-43b1-837b-8543f7df7d08",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Baseline model: MLP classifier with default setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c168a662-e60f-4a05-ad3e-c468bf28fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation values:\n",
      " [0.83333333 0.94444444 0.94444444 0.94444444 0.83333333 1.\n",
      " 1.         1.         1.         1.        ]\n",
      "Cross validation mean: 0.95\n",
      "Cross validation standard deviation:  0.06309898162000303\n",
      "Test accuracy:  0.9722222222222222 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "col_0   0   1  2\n",
      "row_0           \n",
      "0      13   1  0\n",
      "1       0  14  0\n",
      "2       0   0  8\n"
     ]
    }
   ],
   "source": [
    "#Create a MLP (Multi Layer Perceptron) model\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "default_model = MLPClassifier(max_iter = 1400, random_state=42)\n",
    "default_model.fit(X_train, Y_train) #finding weights\n",
    "\n",
    "predictions_default = default_model.predict(X_test)\n",
    "accuracy_1 = accuracy_score(Y_test, predictions_default)\n",
    "scores_1 = cross_val_score(default_model, X, Y, cv=10, scoring=\"accuracy\")\n",
    "#baseline_scores = cross_val_score(baseline_mlp,X, Y,cv=10,scoring='f1_weighted')\n",
    "\n",
    "print(\"Cross validation values:\\n\", scores_1)\n",
    "#print(\"Cross validation f1 value:\", np.mean(baseline_scores))\n",
    "print(\"Cross validation mean:\", scores_1.mean())\n",
    "print(\"Cross validation standard deviation: \", scores_1.std())\n",
    "print(\"Test accuracy: \", accuracy_1, \"\\n\")\n",
    "print(classification_report(Y_test, predictions_default))\n",
    "print(pd.crosstab(Y_test, predictions_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4dba05d-3b35-41d0-9f91-4e9e6dfabb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPEATED Cross validation values:\n",
      " [0.95       0.93333333 0.7748366  0.95555556 0.59607843]\n",
      "REPEATED Cross validation mean: 0.8419607843137256\n",
      "REPEATED Cross validation standard deviation:  0.1399206734733033\n"
     ]
    }
   ],
   "source": [
    "# Split dataset (train/test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "for seed in range(5):\n",
    "    repeated_default_model = MLPClassifier(max_iter = 1400, random_state=seed)\n",
    "    scores = cross_val_score(repeated_default_model, X, Y, cv=10)\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "repeated_default_model.fit(X_train, Y_train)\n",
    "cv_scores = np.array(cv_scores)\n",
    "\n",
    "print(\"REPEATED Cross validation values:\\n\", cv_scores)\n",
    "print(\"REPEATED Cross validation mean:\", cv_scores.mean())\n",
    "print(\"REPEATED Cross validation standard deviation: \", cv_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf201b-caab-4f28-b94a-aa2d6e9b5ae4",
   "metadata": {},
   "source": [
    "**QUESTION 1.1**\n",
    "\n",
    "Above is the MLP classifier built using the standard setup from SK-learn, along with the evaluation of its performance. \n",
    "\n",
    "To ensure that the MLP has enough of time (number of iterations) to learn, we increased the `max_iter` beyond its default value. By experimenting different values, starting at 1000 and increasing to 2000, we gradually narrowed down an appropriate iteration limit. In the end we chose 1400 iterations, as this prevented convergence warnings and ensured that the optimizer completed training before reaching the maximum iteration limit.\n",
    "\n",
    "**Performance evaluation**\n",
    "\n",
    "The 10-fold cross validation (CV) performed on the default model produced an CV mean accuracy of 0.95 with a CV standard deviation of 0.063, indicating strong performance but with some variation across folds. For the current train/test split, the model achieved a test accuracy of 0.972, meaning it performs well on this particular split. \n",
    "\n",
    "To assess stability and generalization more thoroughly, we repeated 10-fold CV five times with different random seeds. Across these repeated runs, the mean CV accuracy was 0.841 with a standard deviation of 0.139. The noticeably lower CV mean and relatively high standard deviation indicate that the model's performance is not very stable and consistent across different folds. This suggests that the model may be somewhat sensitive to how the data is split and does not generalize perfectly across folds of the wine dataset.\n",
    "\n",
    "The classification report for the test set confirms that on this particular split, the model performs extremely well with no major weakness. The overall accuracy is 0.97 meaning that 97% of the test samples were correctly classified. The macro average of 0.98 shows all classes are treated fairly and performs similarily, independent on class sizes. The weighted average of 0.97 confirms strong overall performance taking into consideration of class imbalance. \n",
    "\n",
    "The confusion matrix for the test set shows that only one misclassification appeared, which is minor and likely due the chemical similarities between class 0 and 1. There are no signs of overfitting in this confusion matrix. Overall, results of the classification report and the confusion matrix indicate that the model generalizes well and performs extremely well on this specific test set, although the repeated CV results suggest that its performance may vary depending on the data split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b646e1-87e7-4a1d-9a02-5a03517927b0",
   "metadata": {},
   "source": [
    "**Applying the standard rules of thumb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1eb27ee9-b72d-4d91-bf28-80db6a7ba16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation values:\n",
      " [0.66666667 0.94444444 0.88888889 0.77777778 0.72222222 1.\n",
      " 0.83333333 0.94444444 1.         1.        ]\n",
      "Cross validation mean: 0.8777777777777779\n",
      "Cross validation standard deviation:  0.11600340565456166\n",
      "Test accuracy:  0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       0.61      1.00      0.76        14\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.54      0.64      0.57        36\n",
      "weighted avg       0.63      0.75      0.67        36\n",
      "\n",
      "col_0   0   1\n",
      "row_0        \n",
      "0      13   1\n",
      "1       0  14\n",
      "2       0   8\n"
     ]
    }
   ],
   "source": [
    "#Create a MLP (Multi Layer Perceptron) model\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "rule_of_thumb_model = MLPClassifier(hidden_layer_sizes=(8,), max_iter=3000, random_state=42)\n",
    "rule_of_thumb_model.fit(X_train, Y_train)\n",
    "\n",
    "predictions_rule_of_thumb = rule_of_thumb_model.predict(X_test)\n",
    "accuracy_2 = accuracy_score(Y_test, predictions_rule_of_thumb)\n",
    "scores_2 = cross_val_score(rule_of_thumb_model, X, Y, cv=10, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Cross validation values:\\n\", scores_2)\n",
    "print(\"Cross validation mean:\", scores_2.mean())\n",
    "print(\"Cross validation standard deviation: \", scores_2.std())\n",
    "print(\"Test accuracy: \", accuracy_2)\n",
    "print(classification_report(Y_test, predictions_rule_of_thumb, zero_division=0))\n",
    "print(pd.crosstab(Y_test, predictions_rule_of_thumb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6719fa6-7744-4f68-8db2-71c8b340ea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPEATED Cross validation values:\n",
      " [0.5630719  0.08954248 0.66405229 0.33137255 0.39934641]\n",
      "REPEATED Cross validation mean: 0.4094771241830065\n",
      "REPEATED Cross validation standard deviation:  0.19847468246947164\n"
     ]
    }
   ],
   "source": [
    "# Split dataset (train/test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "for seed in range(5):\n",
    "    repeated_rule_of_thumb_model = MLPClassifier(hidden_layer_sizes=(8,), max_iter = 3000, random_state=seed)\n",
    "    scores = cross_val_score(repeated_rule_of_thumb_model, X, Y, cv=10)\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "repeated_rule_of_thumb_model.fit(X_train, Y_train)\n",
    "cv_scores = np.array(cv_scores)\n",
    "\n",
    "print(\"REPEATED Cross validation values:\\n\", cv_scores)\n",
    "print(\"REPEATED Cross validation mean:\", cv_scores.mean())\n",
    "print(\"REPEATED Cross validation standard deviation: \", cv_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ee767-0ed2-427d-8050-3bde11bcd599",
   "metadata": {},
   "source": [
    "**QUESTION 1.2 and 1.2.1**\n",
    "\n",
    "Above is MLP classifier built in accordance with the rules of the thumb.\n",
    "\n",
    "We increased the value of `max_iter` to 3000 iterations to prevent convergence warnings and ensure that the optimizer completed training before reaching the maximum iteration limit.\n",
    "\n",
    "Based on the wine dataset complexity (13 input features and 3 output classes), we applied the standard rules of the thumb for determining an appropriate hidden layer size for MLP classifier. The rules are applied as follows: \n",
    "\n",
    "**Rule 1: Number of neurons somewhere in-between the size of the input and output layer**\n",
    "\n",
    "The input layer has 13 neurons and the output layer has 3 neurons --> 3-13 neurons\n",
    "\n",
    "**Rule 2: Mean input and output**\n",
    "\n",
    "(13 + 3) / 2 = 8 neurons\n",
    "\n",
    "**Rule 3: Less than twice the input layer**\n",
    "\n",
    "Twice the input size is 26, therefore less than 26 --> 1-25 neurons, however this rule is quite broad and not as informative\n",
    "\n",
    "**Rule 4: Two-thirds rule**\n",
    "\n",
    "(2/3 * 13) + 3 ~= 11-12 neurons\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "Combining the rules, it is reasonable to evaluate hidden layer sizes in the range 3-12 neurons. Among these, 8 neurons is particularly strong candidate as it is supported by multiple rules, 3 rules in total(rule 1-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809f128-3a6e-46fd-9e00-2175e3ff0640",
   "metadata": {},
   "source": [
    "**QUESTION 1.2.2**\n",
    "\n",
    "**Performance evaluation**\n",
    "\n",
    "The 10-fold cross validation (CV) performed on the rules of thumb model produced an CV mean accuracy of 0.877 with a CV standard deviation of 0.116, indicating good overall performance with moderate variation across folds. For the current train/test split, the model achieved a test accuracy of 0.75, reflecting moderate performance.\n",
    "\n",
    "To assess stability and generalization more thoroughly, we repeated 10-fold CV five times with different random seeds. Across these repeated runs, the mean CV accuracy was 0.409 with a standard deviation of 0.198. The drastic drop in CV mean and high standard deviation indicate that the model's performance is highly unstable and inconsistent across different folds. This suggests that the model is sensitive to how the data is split and does not generalize well across folds of the wine dataset.\n",
    "\n",
    "The classification report for the test set shows moderate overall accuracy of 0.75 but poor performance on minority class 2, with low macro average (0.54-0.57) indicating poor fairness across classes and moderate weighted average (0.63-0.67). The confusion matrix confirms that all class 2 samples were misclassified, highlighting difficulty in distinguishing class 2 from class 1, likely due to class imbalance and feature similarity. The model appears underfitted for class 2, failing to capture its characteristic patterns. \n",
    "\n",
    "Overall, results of the classification report and the confusion matrix indicate moderate performance on the test set with particular weakness on the minority class. However, the repeated CV results suggest that the model's performance is unstable and sensitive to different data splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c874a-9a7f-4deb-a697-6e4a48526bfd",
   "metadata": {},
   "source": [
    "**QUESTION 1.3**\n",
    "\n",
    "The best baseline model out of the two previously built models (the default model and the rules of thumb model) is the default model based on their performance metrics. The default model has a much better overall cross-validation mean of 0.841 and relatively lower and more consistent standard deviations across repeats (0.139). In comparison, the rules of thumb model has a drastically lower overall cross-validation mean of 0.409 and high variability across repeats with standard deviation of 0.198. Besides, the default model is easier and simpler to set up, whereas the rules-of-thumb model requires precomputing of the number of neurons, making its setup more complex and time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2dd6ae7d-d4a8-4234-aa4f-c626ed7a959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION RESULTS:\n",
      "{'fit_time': array([0.29855919, 0.26653957, 0.23209405, 0.18866444, 0.32882237]), 'score_time': array([0.01957107, 0.0076313 , 0.00712013, 0.00892186, 0.00858545]), 'test_accuracy': array([0.97222222, 0.97222222, 0.97222222, 1.        , 0.97142857]), 'test_precision_macro': array([0.96969697, 0.96969697, 0.97777778, 1.        , 0.96666667]), 'test_recall_macro': array([0.97619048, 0.97619048, 0.96666667, 1.        , 0.97777778]), 'test_f1_macro': array([0.97178131, 0.97178131, 0.97096189, 1.        , 0.97096189])}\n",
      "\n",
      " UPDATED BASELINE MLP RESULTS:\n",
      "Baseline MLP F1-score (weighted): 0.9766047079701448\n",
      "    \n",
      "\n",
      " PCA TECHNIQUE RESULTS:\n",
      "Original number of features: 13\n",
      "Number of PCA components: 10\n",
      "\n",
      " MLP WITH PCA TECHNIQUE RESULTS:\n",
      "Cross-validated F1-score with PCA: 0.9644972910903492\n",
      "    \n",
      "EVALUATION OF TEST SET RESULTS:\n",
      "Accuracy: 1.0\n",
      "Precision (weighted): 1.0\n",
      "Recall (weighted): 1.0\n",
      "F1-score (weighted): 1.0\n",
      "Confusion matrix:\n",
      " [[14  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "#Data Standarization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform both train and test sets\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Applying balancing agent\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train_scaled, Y_train)\n",
    "X_test_final = X_test_scaled\n",
    "y_test_final = Y_test\n",
    "\n",
    "#Testing improvements through cross validation and accuracy\n",
    "pipeline = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('mlp', MLPClassifier(random_state=42, max_iter=1400))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate with multiple metrics\n",
    "scores = cross_validate(\n",
    "    pipeline, X, Y,\n",
    "    cv=cv,\n",
    "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    ")\n",
    "print(\"DATA PREPARATION RESULTS:\")\n",
    "print(scores)\n",
    "\n",
    "#Model improvements\n",
    "baseline_mlp = MLPClassifier(random_state=42, max_iter=1400)\n",
    "baseline_scores = cross_val_score(baseline_mlp,\n",
    "                                  X_train_resampled, \n",
    "                                  y_train_resampled,\n",
    "                                  cv=cv,\n",
    "                                  scoring='f1_weighted'\n",
    "                                 )\n",
    "print(\"\\n UPDATED BASELINE MLP RESULTS:\")\n",
    "print(\"Baseline MLP F1-score (weighted):\", np.mean(baseline_scores))\n",
    "\n",
    "#Applying PCA Techinque\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_resampled)\n",
    "X_test_pca = pca.transform(X_test_final)\n",
    "\n",
    "print(\"    \")\n",
    "print(\"\\n PCA TECHNIQUE RESULTS:\")\n",
    "print(\"Original number of features:\", X_train.shape[1])\n",
    "print(\"Number of PCA components:\", X_train_pca.shape[1])\n",
    "\n",
    "#Conducting MLP with PCA\n",
    "mlp_pca = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=1000, random_state=42)\n",
    "\n",
    "scores = cross_val_score(mlp_pca, \n",
    "                         X_train_pca, \n",
    "                         y_train_resampled,\n",
    "                         cv=cv, \n",
    "                         scoring='f1_weighted')\n",
    "\n",
    "print(\"\\n MLP WITH PCA TECHNIQUE RESULTS:\")\n",
    "print(\"Cross-validated F1-score with PCA:\", np.mean(scores))\n",
    "\n",
    "#Evaluation of test set\n",
    "mlp_pca.fit(X_train_pca, y_train_resampled)\n",
    "y_pred = mlp_pca.predict(X_test_pca)\n",
    "\n",
    "print(\"    \")\n",
    "print(\"EVALUATION OF TEST SET RESULTS:\")\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, y_pred))\n",
    "print(\"Precision (weighted):\", precision_score(Y_test, y_pred, average='weighted'))\n",
    "print(\"Recall (weighted):\", recall_score(Y_test, y_pred, average='weighted'))\n",
    "print(\"F1-score (weighted):\", f1_score(Y_test, y_pred, average='weighted'))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2a0fd-1425-4650-860f-1f0c7597d16c",
   "metadata": {},
   "source": [
    "**QUESTION 2.1**\n",
    "\n",
    "**Data Preparation**\n",
    "\n",
    "Seeing as how both models are very dependent on how the data is split, one option would be to prepare the data beforehand with techniques such as normalization or standarization in order to reduce the variance and distances among the different values. Also, since in previous assignments we learned that the classes in the dataset are slightly imbalaced, we introduce a balancing component in an attempt to bias and the F1 score. Finally, to ensure that each fold has the same class distribution as the full dataset, we will introduce the stratification.\n",
    "\n",
    "**Model Improvement**\n",
    "\n",
    "In order to improve the model we will first apply the MLP method on the prepared data in order to set a new, possibly improved, baseline. After that we will apply the PCA technique in order to reduce the dimensionality of the data set and remove the possible redundancies. After that , we will train the MLP model with the data obtained from the PCA to  improve MLP training speed and reduce overfitting. Finally we evaluate the test set with all the changes applied in order to verify their effects on the model.\n",
    "\n",
    "As seen by de results, the data preparation allowed for a more stable model across every fold, since the scores in the data preparation are very close to 1. This is further confirmed with the weighted F1 of the new baseline model, which is higher than the original one. When applying the PCA technique, we reduce the 13 original features to 10 main components, preserving the variance and obtaining a perfect confussion matrix, which is the definite proof that the improvements on the dataset and the model have worked, not by outperforming the cross validation test but in the test performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b26e5c00-cbf1-4b3a-b3ed-b737d0fa1acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'mlp__activation': 'relu', 'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': (100, 50), 'mlp__learning_rate_init': 0.001}\n",
      "\n",
      "Best cross-validated F1-score:\n",
      "0.9888678699729315\n"
     ]
    }
   ],
   "source": [
    "#Grid search \n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [\n",
    "        (50,), (100,), (150,),        # one hidden layer\n",
    "        (50,50), (100,50), (100,100)  # two hidden layers\n",
    "    ],    \n",
    "    'mlp__activation': ['relu', 'tanh'],    \n",
    "    'mlp__alpha': [0.0001, 0.001, 0.01],    \n",
    "    'mlp__learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X, Y)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\nBest cross-validated F1-score:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72ee2d3-4dc1-41a7-82d7-4a06e2948704",
   "metadata": {},
   "source": [
    "**QUESTION 2.2**\n",
    "\n",
    "Above is the first implementation of a grid search. Since there are 178 samples in the dataset, we decidet to work with two layers instead of one like in the first examples given in class. Obviously, this parameters will change as the rest of the questions of the assignment are answered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dee2f1-ee1e-41b0-a5db-6ec2d03a61e2",
   "metadata": {},
   "source": [
    "**QUESTION 2.2.1, 2.2.2, 2.2.3**\n",
    "\n",
    "Above, we use grid search to find the optimal combination of hyperparameters:`activation = relu`, `alpha = 0.0001`, `hidden_layer_sizes = (100, 50) ` and `learning_rate_init = 0.001`. In this section, we also explain our choice of parameters and justify the ranges of values we tested.\n",
    "\n",
    "We selected the following hyperparameters for our grid search: \n",
    "- `hidden_layer_sizes` - The wine dataset is relatively small (178 samples) which makes model's capacity particularly important. A network with too few neurons may not be flexible enough to capture underlying patterns and can underfit, while a network with too many neurons may memorize the training data and overfit. For this reason, we included both one-layer and two-layer configurations, to find an appropriate balance between model complexity and generalization. \n",
    "\n",
    "- `activation` - The activation gives the neural network the ability to learn complex patterns, not just straight linear relationships. Therefore we have included two most commonly used activations in MLPs namely relu and tanh. Relu can help with sparse gradients, while tanh is smoother and can perform better when input features are scaled.\n",
    "\n",
    "- `alpha` - This parameter determines how strongly the model tries to keep the weights small to prevent overfitting. Because our dataset is small, regularization is important to help the model generalize well. By testing several values  of `alpha`,  we can find an appropriate balance between fitting the data and avoid overfitting. The selected values cover a reasonable range of regularization strengths:\n",
    "\n",
    "        \n",
    "                0.0001 --> weak regularization\n",
    "                \n",
    "                0.001 --> moderate regularization\n",
    "                \n",
    "                0.01 --> strong regularization\n",
    "\n",
    "\n",
    "- `learning_rate_init` - The learning rate influences how the model updates its weights and how quickly it converges during training (decides how fast and how smoothly the model learns). If the learning rate is too high, the model becomes unstable and can't settle on a good solution. However, if it is too slow, training becomes slow and the model may get stuck before finding the best result. We test two commonly used values (0.001 and 0.01) to identify the most stable and efficient learning rate for the wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44aad522-fb99-4732-84d9-2e044c6f3fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation values:\n",
      " [0.61111111 0.66666667 0.72222222 0.94444444 0.5        0.72222222\n",
      " 1.         0.72222222 0.76470588 0.94117647]\n",
      "Cross validation mean: 0.7594771241830066\n",
      "Cross validation standard deviation:  0.15073970006136728\n",
      "Test accuracy:  0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.93      0.96        14\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "col_0   0   1  2\n",
      "row_0           \n",
      "0      14   0  0\n",
      "1       1  13  0\n",
      "2       0   0  8\n"
     ]
    }
   ],
   "source": [
    "best_param_model = MLPClassifier(\n",
    "    activation = 'relu', \n",
    "    alpha = 0.0001, \n",
    "    hidden_layer_sizes=(100, 50), \n",
    "    learning_rate_init=0.001, \n",
    "    max_iter=3000, \n",
    "    random_state=42\n",
    ")\n",
    "scores_best_param_model = cross_val_score(best_param_model, X, Y, cv=10, scoring=\"accuracy\")\n",
    "\n",
    "best_param_model.fit(X_train, Y_train)\n",
    "predictions_best_param_model = best_param_model.predict(X_test)\n",
    "accuracy_best_param_model = accuracy_score(Y_test, predictions_best_param_model)\n",
    "\n",
    "print(\"Cross validation values:\\n\", scores_best_param_model)\n",
    "print(\"Cross validation mean:\", scores_best_param_model.mean())\n",
    "print(\"Cross validation standard deviation: \", scores_best_param_model.std())\n",
    "print(\"Test accuracy: \", accuracy_best_param_model)\n",
    "\n",
    "print(classification_report(Y_test, predictions_best_param_model))\n",
    "print(pd.crosstab(Y_test, predictions_best_param_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adfce579-949b-43f0-a586-2daa64483d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPEATED Cross validation values:\n",
      " [0.47843137 0.39836601 0.95       0.95       0.62385621]\n",
      "REPEATED Cross validation mean: 0.6801307189542484\n",
      "REPEATED Cross validation standard deviation:  0.23190500381804563\n"
     ]
    }
   ],
   "source": [
    "# Split dataset (train/test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "for seed in range(5):\n",
    "    repeated_best_param_model = MLPClassifier(\n",
    "        activation = 'relu', \n",
    "        alpha = 0.0001, \n",
    "        hidden_layer_sizes=(100, 50), \n",
    "        learning_rate_init=0.001, \n",
    "        max_iter=3000, \n",
    "        random_state=seed\n",
    "    )\n",
    "    scores = cross_val_score(repeated_best_param_model, X, Y, cv=10)\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "repeated_best_param_model.fit(X_train, Y_train)\n",
    "cv_scores = np.array(cv_scores)\n",
    "\n",
    "print(\"REPEATED Cross validation values:\\n\", cv_scores)\n",
    "print(\"REPEATED Cross validation mean:\", cv_scores.mean())\n",
    "print(\"REPEATED Cross validation standard deviation: \", cv_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c0082b-0154-47e5-9902-4c7f2318cb95",
   "metadata": {},
   "source": [
    "**QUESTION 2.2.4**\n",
    "\n",
    "Above is the MLP classifier built using the best setup from grid search, along with the evaluation of its performance. \n",
    "\n",
    "**Performance evaluation**\n",
    "\n",
    "The 10-fold cross validation (CV) performed on the best parameter model produced an CV mean accuracy of 0.759 with a CV standard deviation of 0.150, indicating good overall performance with moderate variation across folds. For the current train/test split, the model achieved a test accuracy of 0.972, meaning it performs well on this particular split. \n",
    "\n",
    "To assess stability and generalization more thoroughly, we repeated 10-fold CV five times with different random seeds. Across these repeated runs, the mean CV accuracy was 0.680 with a standard deviation of 0.231. The noticeably lower CV mean and relatively high standard deviation indicate that the model's performance is not very stable and consistent across different folds. This suggests that the model may be somewhat sensitive to how the data is split and does not generalize perfectly across folds of the wine dataset.\n",
    "\n",
    "The classification report for the test set confirms that on this particular split, the model performs extremely well with no major weakness. The overall accuracy is 0.97 meaning that 97% of the test samples were correctly classified. The macro average of 0.98 shows all classes are treated fairly and performs similarily, independent on class sizes. The weighted average of 0.97 confirms strong overall performance taking into consideration of class imbalance. \n",
    "\n",
    "The confusion matrix for the test set shows that only one misclassification appeared, which is minor and likely due the chemical similarities between class 0 and 1. There are no signs of overfitting in this confusion matrix. Overall, results of the classification report and the confusion matrix indicate that the model generalizes well and performs extremely well on this specific test set, although the repeated CV results suggest that its performance may vary depending on the data split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f22fa-13a2-49ce-8b99-cf6016ca8933",
   "metadata": {},
   "source": [
    "**QUESTION 2.2.5**\n",
    "\n",
    "The best model out of the the baseline(default) model and best parameter model is the default model based on their performance metrics. The default model has a much better overall cross-validation mean of 0.841 and relatively lower and more consistent standard deviations across repeats (0.139). In comparison, the best parameter model has a drastically lower overall cross-validation mean of 0.680 and high variability across repeats with standard deviation of 0.231. \n",
    "\n",
    "On the test set, both the baseline(default) and best-parameter MLP achieved an accuracy of 0.972, weighted F1-score of 0.97 and an almost perfect confusion matrix with only one misclassification. While both models perform almost indentically on this particular test split, the baseline model shows more stable CV performance across folds (CV mean 0.841 vs 0.680, CV standard deviation 0.139 vs 0.231), making it the more reliable choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
